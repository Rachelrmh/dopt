<!DOCTYPE html><html><head>
<meta charset="UTF-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Module dopt.nnet</title>
<link rel="stylesheet" href="../css/style.min.css"/>
<script type="text/javascript" src="../js/script.min.js"></script></head><body onload="setupDdox();"><header></header><nav id="main-nav"><div><noscript><p style="color: red">The search functionality needs JavaScript enabled</p></noscript><div id="symbolSearchPane" style="display: none"><form action="#" method="GET">
<input id="symbolSearch" type="text" name="q" placeholder="Search for symbols" autocomplete="off" onchange="performSymbolSearch(24);" onkeypress="this.onchange();" onpaste="this.onchange();" oninput="this.onchange();" autofocus/></form><ul id="symbolSearchResults" class="symbolList" style="display: none"></ul><script type="application/javascript" src="../symbols.js"></script><script type="application/javascript">var symbolSearchRootDir = "../";
document.getElementById('symbolSearchPane').style.display = 'block';</script></div><ul class="tree-view"><li class="tree-view "><div class="package ">dopt</div><ul class="tree-view"><li class="tree-view collapsed"><div class="package "><a href="../dopt/core.html">core</a></div><ul class="tree-view"><li class="tree-view collapsed"><div class="package ">ops</div><ul class="tree-view"><li><div class="module "><a href="../dopt/core/ops/basic.html">basic</a></div></li><li><div class="module "><a href="../dopt/core/ops/math.html">math</a></div></li><li><div class="module "><a href="../dopt/core/ops/nnet.html">nnet</a></div></li></ul></li><li><div class="module "><a href="../dopt/core/cpu.html">cpu</a></div></li><li><div class="module "><a href="../dopt/core/cuda.html">cuda</a></div></li><li><div class="module "><a href="../dopt/core/grads.html">grads</a></div></li></ul></li><li class="tree-view "><div class="package selected"><a href="../dopt/nnet.html">nnet</a></div><ul class="tree-view"><li><div class="module "><a href="../dopt/nnet/layers.html">layers</a></div></li><li><div class="module "><a href="../dopt/nnet/paraminit.html">paraminit</a></div></li></ul></li><li class="tree-view collapsed"><div class="package ">online</div><ul class="tree-view"><li><div class="module "><a href="../dopt/online/sgd.html">sgd</a></div></li></ul></li></ul></li></ul></div><p id="main-nav-footer">Built with
<a href="https://github.com/MartinNowak/scod">scod</a></p></nav><div id="main-contents"><div><h1>Module dopt.nnet</h1><p>This package contains a neural network framework backed by the automatic differentiation capabilities of dopt.
</p><section><p><ul>        <li><code class="lang-d"><span class="pln">dopt<wbr/></span><span class="pun">.</span><span class="pln">nnet</span></code> contains the <code class="lang-d"><a href="../dopt/nnet/NeuralNetwork.html"><span class="typ">NeuralNetwork</span></a></code> class, which can be used to assist in the construction of
        DAG structured neural networks using operations defined in <code class="lang-d"><a href="../dopt/core.html"><span class="pln">dopt<wbr/></span><span class="pun">.</span><span class="pln">core</span></a></code>.</li>
        <li><code class="lang-d"><a href="../dopt/nnet/layers.html"><span class="pln">dopt<wbr/></span><span class="pun">.</span><span class="pln">nnet<wbr/></span><span class="pun">.</span><span class="pln">layers</span></a></code> contains functions for constructing common layer types.</li>
        <li><code class="lang-d"><a href="../dopt/nnet/paraminit.html"><span class="pln">dopt<wbr/></span><span class="pun">.</span><span class="pln">nnet<wbr/></span><span class="pun">.</span><span class="pln">paraminit</span></a></code> contains several different schemes for initialising network parameters.</li>
    </ul>
</p>
</section>

<section><section><h2>Examples</h2>
<pre class="code"><code class="lang-d"><span class="typ">void </span><span class="pln">main</span><span class="pun">(</span><span class="typ">string</span><span class="pun">[] </span><span class="pln">args</span><span class="pun">)
{
    </span><span class="kwd">import <a href="../dopt/core.html"></span><span class="pln">dopt<wbr/></span><span class="pun">.</span><span class="pln">core</span></a><span class="pun">;
    </span><span class="kwd">import </span><span class="pln">dopt<wbr/></span><span class="pun">.</span><span class="pln">nnet</span><span class="pun">;
    </span><span class="kwd">import </span><span class="pln">dopt<wbr/></span><span class="pun">.</span><span class="pln">online</span><span class="pun">;

    </span><span class="com">//Load the MNIST data---this function can be found in examples/mnist.d
    </span><span class="kwd">auto </span><span class="pln">data </span><span class="pun">= </span><span class="pln">loadMNIST</span><span class="pun">(</span><span class="pln">args</span><span class="pun">[</span><span class="lit">1</span><span class="pun">]);

    </span><span class="com">//Create variables representing the inputs to our network
    </span><span class="kwd">auto </span><span class="pln">features </span><span class="pun">= </span><span class="pln">float32</span><span class="pun">([</span><span class="lit">100</span><span class="pun">, </span><span class="lit">1</span><span class="pun">, </span><span class="lit">28</span><span class="pun">, </span><span class="lit">28</span><span class="pun">]);
    </span><span class="kwd">auto </span><span class="pln">labels </span><span class="pun">= </span><span class="pln">float32</span><span class="pun">([</span><span class="lit">100</span><span class="pun">, </span><span class="lit">10</span><span class="pun">]);

    </span><span class="com">//This chunk of code takes advantage of D's uniform function call syntax to chain some layers together
    </span><span class="kwd">auto </span><span class="pln">layers </span><span class="pun">= </span><span class="pln">dataSource</span><span class="pun">(</span><span class="pln">features</span><span class="pun">)
                 <wbr/>.</span><span class="pln">convolutional</span><span class="pun">(</span><span class="lit">32</span><span class="pun">, [</span><span class="lit">5</span><span class="pun">, </span><span class="lit">5</span><span class="pun">])
                 <wbr/>.</span><span class="pln">relu</span><span class="pun">()
                 <wbr/>.</span><span class="pln">maxPool</span><span class="pun">([</span><span class="lit">2</span><span class="pun">, </span><span class="lit">2</span><span class="pun">])
                 <wbr/>.</span><span class="pln">convolutional</span><span class="pun">(</span><span class="lit">32</span><span class="pun">, [</span><span class="lit">5</span><span class="pun">, </span><span class="lit">5</span><span class="pun">])
                 <wbr/>.</span><span class="pln">relu</span><span class="pun">()
                 <wbr/>.</span><span class="pln">maxPool</span><span class="pun">([</span><span class="lit">2</span><span class="pun">, </span><span class="lit">2</span><span class="pun">])
                 <wbr/>.</span><span class="pln">dense</span><span class="pun">(</span><span class="lit">10</span><span class="pun">)
                 <wbr/>.</span><span class="pln">softmax</span><span class="pun">();

    </span><span class="com">//Use the NeuralNetwork helper class to organise all the parameters
    </span><span class="kwd">auto </span><span class="pln">network </span><span class="pun">= </span><span class="kwd">new <a href="../dopt/nnet/NeuralNetwork.html"></span><span class="typ">NeuralNetwork</span></a><span class="pun">([</span><span class="pln">layers</span><span class="pun">, </span><span class="pln">layers<wbr/></span><span class="pun">.</span><span class="pln">crossEntropy</span><span class="pun">(</span><span class="pln">dataSource</span><span class="pun">(</span><span class="pln">labels</span><span class="pun">))]);

    </span><span class="com">//Create an updater using one of the algorithms in dopt.online
    </span><span class="kwd">auto </span><span class="pln">updater </span><span class="pun">= </span><span class="pln">sgd</span><span class="pun">(</span><span class="pln">network<wbr/></span><span class="pun">.</span><span class="pln">loss</span><span class="pun">, </span><span class="kwd">cast</span><span class="pun">(</span><span class="typ">Operation</span><span class="pun">[])</span><span class="pln">network<wbr/></span><span class="pun">.</span><span class="pln">parameters</span><span class="pun">);

    </span><span class="com">//Train the network using the data we loaded earlier
    </span><span class="kwd">foreach</span><span class="pun">(</span><span class="pln">fs</span><span class="pun">, </span><span class="pln">ls</span><span class="pun">; </span><span class="pln">zip</span><span class="pun">(</span><span class="pln">data<wbr/></span><span class="pun">.</span><span class="pln">trainFeatures<wbr/></span><span class="pun">.</span><span class="pln">chunks</span><span class="pun">(</span><span class="lit">100</span><span class="pun">), </span><span class="pln">data<wbr/></span><span class="pun">.</span><span class="pln">trainLabels<wbr/></span><span class="pun">.</span><span class="pln">chunks</span><span class="pun">(</span><span class="lit">100</span><span class="pun">)))
    {
        </span><span class="kwd">auto </span><span class="pln">loss </span><span class="pun">= </span><span class="pln">updater</span><span class="pun">([
            </span><span class="pln">features</span><span class="pun">: </span><span class="typ">Buffer</span><span class="pun">(</span><span class="pln">fs<wbr/></span><span class="pun">.</span><span class="pln">joiner</span><span class="pun">()<wbr/>.</span><span class="pln">array</span><span class="pun">()),
            </span><span class="pln">labels</span><span class="pun">: </span><span class="typ">Buffer</span><span class="pun">(</span><span class="pln">ls<wbr/></span><span class="pun">.</span><span class="pln">joiner</span><span class="pun">()<wbr/>.</span><span class="pln">array</span><span class="pun">())
        ]);

        </span><span class="kwd">import </span><span class="pln">std<wbr/></span><span class="pun">.</span><span class="pln">stdio</span><span class="pun">;
        </span><span class="pln">writeln</span><span class="pun">(</span><span class="pln">loss</span><span class="pun">);
    }
}</span></code></pre>
</section>
</section><section><h2>Classes</h2><table>
<col class="caption"/>
<tr><th>Name</th><th>Description</th></tr><tr><td><code><a id="Layer" class="["public"]" href="../dopt/nnet/Layer.html">Layer</a></code></td><td>Represents a layer of a neural network.
</td></tr><tr><td><code><a id="NeuralNetwork" class="["public"]" href="../dopt/nnet/NeuralNetwork.html">NeuralNetwork</a></code></td><td>This class provides an simple way to construct neural networks that can be trained with the <code class="lang-d"><span class="pln">dopt<wbr/></span><span class="pun">.</span><span class="pln">online</span></code>
    package.
</td></tr></table></section></div><footer><div id="license-info"><p>Henry Gouk
</p>


</div></footer></div></body></html>