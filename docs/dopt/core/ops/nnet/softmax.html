<!DOCTYPE html><html><head>
<meta charset="UTF-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Function softmax</title>
<link rel="stylesheet" href="../../../../css/style.min.css"/>
<script type="text/javascript" src="../../../../js/script.min.js"></script></head><body onload="setupDdox();"><header></header><nav id="main-nav"><div><noscript><p style="color: red">The search functionality needs JavaScript enabled</p></noscript><div id="symbolSearchPane" style="display: none"><form action="#" method="GET">
<input id="symbolSearch" type="text" name="q" placeholder="Search for symbols" autocomplete="off" onchange="performSymbolSearch(24);" onkeypress="this.onchange();" onpaste="this.onchange();" oninput="this.onchange();" autofocus/></form><ul id="symbolSearchResults" class="symbolList" style="display: none"></ul><script type="application/javascript" src="../../../../symbols.js"></script><script type="application/javascript">var symbolSearchRootDir = "../../../../";
document.getElementById('symbolSearchPane').style.display = 'block';</script></div><ul class="tree-view"><li class="tree-view "><div class="package ">dopt</div><ul class="tree-view"><li class="tree-view "><div class="package "><a href="../../../../dopt/core.html">core</a></div><ul class="tree-view"><li class="tree-view "><div class="package ">ops</div><ul class="tree-view"><li><div class="module "><a href="../../../../dopt/core/ops/basic.html">basic</a></div></li><li><div class="module "><a href="../../../../dopt/core/ops/math.html">math</a></div></li><li><div class="module selected"><a href="../../../../dopt/core/ops/nnet.html">nnet</a></div></li></ul></li><li><div class="module "><a href="../../../../dopt/core/cpu.html">cpu</a></div></li><li><div class="module "><a href="../../../../dopt/core/cuda.html">cuda</a></div></li><li><div class="module "><a href="../../../../dopt/core/grads.html">grads</a></div></li></ul></li><li class="tree-view collapsed"><div class="package ">nnet</div><ul class="tree-view"><li class="tree-view collapsed"><div class="package "><a href="../../../../dopt/nnet/layers.html">layers</a></div><ul class="tree-view"><li><div class="module "><a href="../../../../dopt/nnet/layers/batchnorm.html">batchnorm</a></div></li><li><div class="module "><a href="../../../../dopt/nnet/layers/conv.html">conv</a></div></li><li><div class="module "><a href="../../../../dopt/nnet/layers/datasource.html">datasource</a></div></li><li><div class="module "><a href="../../../../dopt/nnet/layers/dense.html">dense</a></div></li><li><div class="module "><a href="../../../../dopt/nnet/layers/dropout.html">dropout</a></div></li><li><div class="module "><a href="../../../../dopt/nnet/layers/maxpool.html">maxpool</a></div></li><li><div class="module "><a href="../../../../dopt/nnet/layers/relu.html">relu</a></div></li><li><div class="module "><a href="../../../../dopt/nnet/layers/softmax.html">softmax</a></div></li></ul></li><li><div class="module "><a href="../../../../dopt/nnet/losses.html">losses</a></div></li><li><div class="module "><a href="../../../../dopt/nnet/networks.html">networks</a></div></li><li><div class="module "><a href="../../../../dopt/nnet/parameters.html">parameters</a></div></li></ul></li><li class="tree-view collapsed"><div class="package "><a href="../../../../dopt/online.html">online</a></div><ul class="tree-view"><li><div class="module "><a href="../../../../dopt/online/adam.html">adam</a></div></li><li><div class="module "><a href="../../../../dopt/online/sgd.html">sgd</a></div></li></ul></li></ul></li></ul></div><p id="main-nav-footer">Built with
<a href="https://github.com/MartinNowak/scod">scod</a></p></nav><div id="main-contents"><div><h1>Function softmax</h1><p>Creates an operation representing the computation required for a softmax layer.
</p><div class="prototype"><code class="lang-d"><div class="single-prototype">
<span class="pln">dopt<wbr/></span><span class="pun">.</span><span class="pln">core<wbr/></span><span class="pun">.</span><span class="pln">ops<wbr/></span><span class="pun">.</span><span class="typ">Operation</span> <span class="pln">softmax</span>
<span class="pun">(</span>
<br/>
&nbsp;&nbsp;<span class="pln">dopt<wbr/></span><span class="pun">.</span><span class="pln">core<wbr/></span><span class="pun">.</span><span class="pln">ops<wbr/></span><span class="pun">.</span><span class="typ">Operation</span> <span class="pln">inputs</span><span class="pun">,</span>
<br/>
&nbsp;&nbsp;<span class="typ">string</span> <span class="pln">mod</span> <span class="pun">=</span> <span class="kwd">__MODULE__</span><span class="pun">,</span>
<br/>
&nbsp;&nbsp;<span class="typ">ulong</span> <span class="pln">line</span> <span class="pun">=</span> <span class="kwd">cast</span><span class="pun">(</span><span class="typ">ulong</span><span class="pun">)</span><span class="kwd">__LINE__</span>
<br/>
<span class="pun">)</span><span class="pun">;</span></div></code></div><section></section>

<section><h2>Parameters</h2>
<table><col class="caption"><tr><th>Name</th><th>Description</th></tr>
<tr><td id="inputs">inputs</td><td> The inputs to the softmax function.</td></tr>
</table>
</section>
<section><h2>Returns</h2>
<p>The operation.
</p>
</section>
<section><h2>Example</h2>

<pre class="code"><code class="lang-d"><span class="kwd">import </span><span class="pln">std<wbr/></span><span class="pun">.</span><span class="pln">math </span><span class="pun">: </span><span class="pln">approxEqual</span><span class="pun">;
</span><span class="kwd">import <a href="../../../../dopt/core/cpu.html"></span><span class="pln">dopt<wbr/></span><span class="pun">.</span><span class="pln">core<wbr/></span><span class="pun">.</span><span class="pln">cpu</span></a><span class="pln"> </span><span class="pun">: </span><span class="pln">evaluateCUDA</span><span class="pun">;

</span><span class="kwd">auto </span><span class="pln">y </span><span class="pun">= </span><span class="pln">float32</span><span class="pun">([</span><span class="lit">1</span><span class="pun">, </span><span class="lit">5</span><span class="pun">], [</span><span class="lit">1.0f</span><span class="pun">, </span><span class="lit">2.0f</span><span class="pun">, </span><span class="lit">3.0f</span><span class="pun">, </span><span class="lit">1.0f</span><span class="pun">, </span><span class="lit">2.0f</span><span class="pun">])<wbr/>.</span><span class="pln">softmax</span><span class="pun">();

</span><span class="kwd">assert</span><span class="pun">(</span><span class="pln">approxEqual</span><span class="pun">(
    </span><span class="pln">y<wbr/></span><span class="pun">.</span><span class="pln">evaluateCUDA</span><span class="pun">()<wbr/>.</span><span class="pln">as</span><span class="pun">!</span><span class="typ">float</span><span class="pun">,
    [</span><span class="lit">0.0674508</span><span class="pun">, </span><span class="lit">0.18335</span><span class="pun">, </span><span class="lit">0.498398</span><span class="pun">, </span><span class="lit">0.0674508</span><span class="pun">, </span><span class="lit">0.18335</span><span class="pun">]
));

</span></code></pre>
</section>
</div><footer><div id="license-info"><p>Henry Gouk
</p>


</div></footer></div></body></html>