<!DOCTYPE html><html><head>
<meta charset="UTF-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Module dopt.core.ops.nnet</title>
<link rel="stylesheet" href="../../../css/style.min.css"/>
<script type="text/javascript" src="../../../js/script.min.js"></script></head><body onload="setupDdox();"><header></header><nav id="main-nav"><div><noscript><p style="color: red">The search functionality needs JavaScript enabled</p></noscript><div id="symbolSearchPane" style="display: none"><form action="#" method="GET">
<input id="symbolSearch" type="text" name="q" placeholder="Search for symbols" autocomplete="off" onchange="performSymbolSearch(24);" onkeypress="this.onchange();" onpaste="this.onchange();" oninput="this.onchange();" autofocus/></form><ul id="symbolSearchResults" class="symbolList" style="display: none"></ul><script type="application/javascript" src="../../../symbols.js"></script><script type="application/javascript">var symbolSearchRootDir = "../../../";
document.getElementById('symbolSearchPane').style.display = 'block';</script></div><ul class="tree-view"><li class="tree-view "><div class="package ">dopt</div><ul class="tree-view"><li class="tree-view "><div class="package "><a href="../../../dopt/core.html">core</a></div><ul class="tree-view"><li class="tree-view "><div class="package "><a href="../../../dopt/core/ops.html">ops</a></div><ul class="tree-view"><li><div class="module "><a href="../../../dopt/core/ops/basic.html">basic</a></div></li><li><div class="module "><a href="../../../dopt/core/ops/math.html">math</a></div></li><li><div class="module selected"><a href="../../../dopt/core/ops/nnet.html">nnet</a></div></li><li><div class="module "><a href="../../../dopt/core/ops/random.html">random</a></div></li></ul></li><li><div class="module "><a href="../../../dopt/core/grads.html">grads</a></div></li></ul></li><li class="tree-view collapsed"><div class="package "><a href="../../../dopt/nnet.html">nnet</a></div><ul class="tree-view"><li class="tree-view collapsed"><div class="package "><a href="../../../dopt/nnet/layers.html">layers</a></div><ul class="tree-view"><li><div class="module "><a href="../../../dopt/nnet/layers/batchnorm.html">batchnorm</a></div></li><li><div class="module "><a href="../../../dopt/nnet/layers/conv.html">conv</a></div></li><li><div class="module "><a href="../../../dopt/nnet/layers/datasource.html">datasource</a></div></li><li><div class="module "><a href="../../../dopt/nnet/layers/dense.html">dense</a></div></li><li><div class="module "><a href="../../../dopt/nnet/layers/dropout.html">dropout</a></div></li><li><div class="module "><a href="../../../dopt/nnet/layers/maxpool.html">maxpool</a></div></li><li><div class="module "><a href="../../../dopt/nnet/layers/relu.html">relu</a></div></li><li><div class="module "><a href="../../../dopt/nnet/layers/softmax.html">softmax</a></div></li></ul></li><li><div class="module "><a href="../../../dopt/nnet/losses.html">losses</a></div></li><li><div class="module "><a href="../../../dopt/nnet/networks.html">networks</a></div></li><li><div class="module "><a href="../../../dopt/nnet/parameters.html">parameters</a></div></li></ul></li><li class="tree-view collapsed"><div class="package "><a href="../../../dopt/online.html">online</a></div><ul class="tree-view"><li><div class="module "><a href="../../../dopt/online/adam.html">adam</a></div></li><li><div class="module "><a href="../../../dopt/online/amsgrad.html">amsgrad</a></div></li><li><div class="module "><a href="../../../dopt/online/sgd.html">sgd</a></div></li></ul></li><li><div class="module "><a href="../../../dopt/cpu.html">cpu</a></div></li><li><div class="module "><a href="../../../dopt/cuda.html">cuda</a></div></li></ul></li></ul></div><p id="main-nav-footer">Built with
<a href="https://github.com/MartinNowak/scod">scod</a></p></nav><div id="main-contents"><div><h1>Module dopt.core.ops.nnet</h1><p>Contains common neural network operations.
</p><section><p>These operations are currently only implemented for the CUDA backend.
</p>
</section>

<section></section><section><h2>Functions</h2><table>
<col class="caption"/>
<tr><th>Name</th><th>Description</th></tr><tr><td><code><a id="convolution" class="[&quot;public&quot;]" href="../../../dopt/core/ops/nnet/convolution.html">convolution</a><span class="decoration">(features, filters, padding, stride, mod, line)</span></code></td><td>Creates a convolution operation that performs the computation required to implement a convolutional layer.
</td></tr><tr><td><code><a id="convolutionFeaturesGrad" class="[&quot;public&quot;]" href="../../../dopt/core/ops/nnet/convolutionFeaturesGrad.html">convolutionFeaturesGrad</a><span class="decoration">(parentGrad, filters, featuresShape, padding, stride, mod, line)</span></code></td><td>Creates an operation representing the derivative of a convolution operation with respect to the feature maps.
</td></tr><tr><td><code><a id="convolutionFiltersGrad" class="[&quot;public&quot;]" href="../../../dopt/core/ops/nnet/convolutionFiltersGrad.html">convolutionFiltersGrad</a><span class="decoration">(parentGrad, features, filtersShape, padding, stride, mod, line)</span></code></td><td>Creates an operation representing the derivative of a convolution operation with respect to the filters.
</td></tr><tr><td><code><a id="convolutionTranspose" class="[&quot;public&quot;]" href="../../../dopt/core/ops/nnet/convolutionTranspose.html">convolutionTranspose</a><span class="decoration">(features, filters, padding, stride, mod, line)</span></code></td><td>Creates a transposed convolution operation (also known, incorrectly, as deconvolution).
</td></tr><tr><td><code><a id="maxpool" class="[&quot;public&quot;]" href="../../../dopt/core/ops/nnet/maxpool.html">maxpool</a><span class="decoration">(features, dims, mod, line)</span></code></td><td>Creates a max pool operation that performs the computation required to implement a max pooling layer.
</td></tr><tr><td><code><a id="maxpoolGrad" class="[&quot;public&quot;]" href="../../../dopt/core/ops/nnet/maxpoolGrad.html">maxpoolGrad</a><span class="decoration">(parentGrad, op, mod, line)</span></code></td><td>Creates an operation representing the derivative of a maxpool operation with respect to the feature maps.
</td></tr><tr><td><code><a id="relu" class="[&quot;public&quot;]" href="../../../dopt/core/ops/nnet/relu.html">relu</a><span class="decoration">(inputs, mod, line)</span></code></td><td>Creates an operation representing the computation required for a ReLU layer.
</td></tr><tr><td><code><a id="softmax" class="[&quot;public&quot;]" href="../../../dopt/core/ops/nnet/softmax.html">softmax</a><span class="decoration">(inputs, mod, line)</span></code></td><td>Creates an operation representing the computation required for a softmax layer.
</td></tr><tr><td><code><a id="softmaxGrad" class="[&quot;public&quot;]" href="../../../dopt/core/ops/nnet/softmaxGrad.html">softmaxGrad</a><span class="decoration">(parentGrad, op, mod, line)</span></code></td><td>Creates an operation representing the gradient of the softmax function.
</td></tr></table></section></div><footer><div id="license-info"><p>Henry Gouk
</p>


</div></footer></div></body></html>